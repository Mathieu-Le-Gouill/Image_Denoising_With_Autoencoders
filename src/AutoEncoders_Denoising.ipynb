{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_size=1024\n",
    "coef_down_sizing = image_size/2040.0\n",
    "\n",
    "crop_width = 256\n",
    "crop_height = 256\n",
    "\n",
    "assert image_size % crop_width == 0\n",
    "\n",
    "dataset_path = \"DIV2K/\"\n",
    "\n",
    "def show_img_with_matplotlib(color_img, title, pos, figsize=(10, 7)):\n",
    "    \"\"\"Shows an image using matplotlib capabilities\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    # Convert BGR image to RGB\n",
    "    img_RGB = color_img[:, :, ::-1]\n",
    "\n",
    "    plt.imshow(img_RGB)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def load_images_from_dir(dossier_images) :\n",
    "    images = []\n",
    "    \n",
    "    fichiers = os.listdir(dossier_images)\n",
    "\n",
    "    fichiers_images = [f for f in fichiers]\n",
    "\n",
    "    \n",
    "    for i, fichier in enumerate(fichiers_images):\n",
    "        chemin_complet = os.path.join(dossier_images, fichier)\n",
    "        image = cv2.imread(chemin_complet)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "            \n",
    "        if i <= 3:\n",
    "            show_img_with_matplotlib(image, f\"image {i}\", i)  \n",
    "            \n",
    "    return images\n",
    "\n",
    "y_train = load_images_from_dir(dataset_path + \"DIV2K_train_HR\")\n",
    "y_valid = load_images_from_dir(dataset_path + \"DIV2K_valid_HR\")\n",
    "\n",
    "print(len(y_train)+len(y_valid),\"images loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    preprocessed_images = []\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        # Redimensionnement de l'image en conservant les proportions d'origine\n",
    "        resized_img = cv2.resize(img, (int(width * coef_down_sizing), int(height * coef_down_sizing)), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Affichage de l'image prétraitée\n",
    "        if i <= 3:\n",
    "            show_img_with_matplotlib(resized_img, f\"image {i}\", i)\n",
    "            \n",
    "        preprocessed_images.append(resized_img)\n",
    "\n",
    "    return preprocessed_images\n",
    "\n",
    "y_train = preprocess_images(y_train)\n",
    "y_valid = preprocess_images(y_valid)\n",
    "\n",
    "print(\"Number traning images :\",len(y_train))\n",
    "print(\"Number validation images :\",len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise_and_resize(images, scale_factor_range=(0.25, 0.45), noise_std_range=(3.5, 10.0)):\n",
    "    noisy_images = []\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        \n",
    "        scale_factor = np.random.uniform(*scale_factor_range)\n",
    "        noise_std = np.random.uniform(*noise_std_range)\n",
    "        \n",
    "        # Distortion de l'image\n",
    "        width = int(img.shape[1] * scale_factor)\n",
    "        height = int(img.shape[0] * scale_factor)\n",
    "        dimensions = (width, height)\n",
    "        reduced_image = cv2.resize(img, dimensions, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        \n",
    "        resized_image = cv2.resize(reduced_image, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Ajout d'un bruit gaussien aléatoire\n",
    "        noise_r = np.random.normal(scale=noise_std, size=img.shape[:2])\n",
    "        noise_g = np.random.normal(scale=noise_std, size=img.shape[:2])\n",
    "        noise_b = np.random.normal(scale=noise_std, size=img.shape[:2])\n",
    "\n",
    "        \n",
    "        noise = np.stack((noise_r, noise_g, noise_b), axis=-1)\n",
    "\n",
    "        \n",
    "        noisy_img = resized_image + noise\n",
    "        \n",
    "        \n",
    "        noisy_img = np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        if i <= 2:\n",
    "            show_img_with_matplotlib(noisy_img, f\"noisy image {i}\", i)\n",
    "        \n",
    "        noisy_images.append(noisy_img) \n",
    "        \n",
    "    return noisy_images\n",
    "\n",
    "\n",
    "x_train = add_gaussian_noise_and_resize(y_train)\n",
    "x_valid = add_gaussian_noise_and_resize(y_valid)\n",
    "\n",
    "print(\"Number traning images :\",len(x_train))\n",
    "print(\"Number validation images :\",len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crop_images(x, y, crop_width=crop_width, crop_height=crop_height):\n",
    "    x_crops = []\n",
    "    y_crops = []\n",
    "    print(x[0].shape)\n",
    "    for i in range(len(x)):\n",
    "        for h in range(0,x[i].shape[0] // crop_height * crop_height,crop_height):\n",
    "            for w in range(0,x[i].shape[1] // crop_width * crop_width, crop_width):\n",
    "                x_crops.append(x[i][h:h+crop_height, w:w+crop_width, :])\n",
    "                y_crops.append(y[i][h:h+crop_height, w:w+crop_width, :])\n",
    "    \n",
    "    return np.stack(x_crops), np.stack(y_crops)\n",
    "\n",
    "\n",
    "x_train_crops, y_train_crops = crop_images(x_train, y_train)\n",
    "x_valid_crops, y_valid_crops = crop_images(x_valid, y_valid)\n",
    "\n",
    "\n",
    "print(\"Train data shapes:\", x_train_crops.shape, y_train_crops.shape)\n",
    "print(\"Validation data shapes:\", x_valid_crops.shape, y_valid_crops.shape)\n",
    "\n",
    "for i in range(30,34):\n",
    "    show_img_with_matplotlib(x_train_crops[i], f\"x cropped image {i}\", i)\n",
    "    show_img_with_matplotlib(y_train_crops[i], f\"y cropped image {i}\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_crops = x_train_crops / 255.0\n",
    "y_train_crops = y_train_crops / 255.0\n",
    "\n",
    "x_valid_crops = x_valid_crops / 255.0\n",
    "y_valid_crops = y_valid_crops / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Encodeur\n",
    "encoder_input = tf.keras.layers.Input(shape=(crop_width, crop_height, 3))\n",
    "\n",
    "conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(encoder_input)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv1)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "\n",
    "pool1 = MaxPooling2D((2, 2), padding='same')(conv1)\n",
    "\n",
    "conv2 = Conv2D(32, (3, 3), padding='same', activation='relu')(pool1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Conv2D(32, (3, 3), padding='same', activation='relu')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "\n",
    "pool2 = MaxPooling2D((2, 2), padding='same')(conv2)\n",
    "\n",
    "conv3 = Conv2D(16, (3, 3), padding='same', activation='relu')(pool2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Conv2D(16, (3, 3), padding='same', activation='relu')(conv3)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "pool3 = MaxPooling2D((2, 2), padding='same')(conv3)\n",
    "\n",
    "conv4 = Conv2D(8, (3, 3), padding='same', activation='relu')(pool3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Conv2D(8, (3, 3), padding='same', activation='relu')(conv4)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "# Décodeur\n",
    "up1 = UpSampling2D((2, 2))(conv4)\n",
    "\n",
    "concat1 = concatenate([conv3, up1], axis=-1)\n",
    "conv5 = Conv2D(16, (3, 3), padding='same', activation='relu')(concat1)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "conv5 = Conv2D(16, (3, 3), padding='same', activation='relu')(conv5)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "up2 = UpSampling2D((2, 2))(conv5)\n",
    "\n",
    "concat2 = concatenate([conv2, up2], axis=-1)\n",
    "conv6 = Conv2D(32, (3, 3), padding='same', activation='relu')(concat2)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "conv6 = Conv2D(32, (3, 3), padding='same', activation='relu')(conv6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "up3 = UpSampling2D((2, 2))(conv6)\n",
    "\n",
    "concat3 = concatenate([conv1, up3], axis=-1)\n",
    "conv7 = Conv2D(64, (3, 3), padding='same', activation='relu')(concat3)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "output = Conv2D(3, (1, 1), activation='sigmoid', padding='same')(conv7)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(inputs=encoder_input, outputs=output)\n",
    "\n",
    "def psnr(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[psnr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def data_generator(x, y, batch_size):\n",
    "    num_samples = len(x)\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        yield x[batch_indices], y[batch_indices]\n",
    "\n",
    "\n",
    "batch_size = int(image_size/crop_width)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(x_train_crops, y_train_crops, batch_size), \n",
    "    output_types=(tf.float32, tf.float32), \n",
    "    output_shapes=(\n",
    "        tf.TensorShape([batch_size, crop_width, crop_height, 3]), \n",
    "        tf.TensorShape([batch_size, crop_width, crop_height, 3])\n",
    "    )\n",
    ")\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(x_valid_crops, y_valid_crops, batch_size), \n",
    "    output_types=(tf.float32, tf.float32), \n",
    "    output_shapes=(\n",
    "        tf.TensorShape([batch_size, crop_width, crop_height, 3]), \n",
    "        tf.TensorShape([batch_size, crop_width, crop_height, 3])\n",
    "    )\n",
    ")\n",
    "valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 30))\n",
    "for i, (x, y) in enumerate(train_dataset.take(10)):\n",
    "    show_img_with_matplotlib(x[0].numpy(), f\"x image {i}\", 2*i+1)\n",
    "    show_img_with_matplotlib(y[0].numpy(), f\"y image {i}\", 2*i+2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce135d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 60:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 20:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Entraîner le modèle avec les images bruitées comme entrées et les images originales comme labels\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=80,\n",
    "                    shuffle=False,\n",
    "                    validation_data=valid_dataset,\n",
    "                    callbacks=[lr_scheduler])  # Utilisation du jeu de validation\n",
    "\n",
    "# Test du modèle\n",
    "decoded_imgs = model.predict(x_valid_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cacd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_auto_encoder_image_denoising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f508e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# Utilisation de la fonction pour afficher la courbe d'apprentissage\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea250cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 30))\n",
    "for i in range(0,50):\n",
    "    show_img_with_matplotlib(x_valid_crops[i], f\"input image {i}\", i)\n",
    "    show_img_with_matplotlib(decoded_imgs[i], f\"predicted image {i}\", i)\n",
    "    show_img_with_matplotlib(decoded_imgs[i], f\"target image {i}\", i)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f5ca7-9114-4a98-aa91-6ebf929c463b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
